{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Nama : Muhammad Nurul Mustofa**   \n",
        "**Kelas : 3A**  \n",
        "**Nim : 2241720022**  "
      ],
      "metadata": {
        "id": "SMAckMlQSZwi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "879f83tOSWI8"
      },
      "source": [
        "# **Job Sheet 11: Convolutional Neural Network (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgK7-qrSWI9"
      },
      "source": [
        "# **ğŸ¦Praktikum 1**\n",
        "## Klasifikasi citra kucing dan anjing\n",
        "\n",
        "## **Deskripsi**\n",
        "Pada praktikum ini kita akan membuat model klasifikasi CNN sederhana pada kasus citra kucing dan anjing.\n",
        "\n",
        "## **Dataset**\n",
        "Dataset merupakan data citra anjing dan kucing yang telah dibagi menjadi data training dan data testing. Dikarenakan data cukup besar, pastikan koneksi Anda sebelum mengunduh dataset.\n",
        "\n",
        "[https://drive.google.com/file/d/1vYrqBI1VmiXXJd5sgtKK2nuQvC8T1ryb/view](https://)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSxtPqbMSWI9"
      },
      "source": [
        "## **Langkah 1 - Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSVxJ_ZKSWI-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkrcGI79SWI-"
      },
      "source": [
        "## **Langkah 2 - Pra Pengolahan Data**\n",
        "Pada tahap ini kita akan sedikit melakukan manipulasi pada citra yang digunakan. Manipulasi yang dilakukan diantaranya adalah normalisasi nilai piksel, koreksi kemiringan, pembesaran (zoom), dan flip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuBhi9J3SWI-"
      },
      "source": [
        "### **Langkah 2.1. Pra Pengolahan Data Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THlGR3sbSWI_",
        "outputId": "298803ca-6c93-4a7e-892c-f572d45f3f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('data/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOnnDInsSWI_"
      },
      "source": [
        "### **Langkah 2.2. Pra Pengolahan Data Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LP-oo3GSWI_",
        "outputId": "b48bcfda-c4a1-4c3e-d752-a139b0b582d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('data/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2_DvOkASWJA"
      },
      "source": [
        "## **Langkah 3 - Pembuatan Model CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDZvDvW1SWJA"
      },
      "source": [
        "### **Langkah 3.1.  - Inisiasi Model CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ldyAyR-SWJA"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh1rdoC0SWJA"
      },
      "source": [
        "### **Langkah 3.2. - Pembuatan Layer Konvolusi 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RshIDzqWSWJB",
        "outputId": "11227364-1da5-4c62-fbab-ab6839b0b036"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\Machine_Learning_2024\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BshTEbsbSWJB"
      },
      "source": [
        "### **Langkah 3.3 - Pembuatan Layer Pooling 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAc7vvKnSWJB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abzYZ1kHSWJB"
      },
      "source": [
        "### **Langkah 3.4 - Pembuatan Layer Konvolusi 2 dan Pooling 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWiCSVBvSWJB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RldjBRFhSWJB"
      },
      "source": [
        "### **Langkah 3.5 - Flattening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hkZMZFYSWJB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaEAS0EFSWJB"
      },
      "source": [
        "### **Langkah 3.6 - Fully Connected Layer 1 (Input)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV4v2APASWJB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAXOwwsVSWJB"
      },
      "source": [
        "### **Langkah 3.7 - Fully Connected Layer 2 (Output)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmmzeF9gSWJB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh-kw2UvSWJB"
      },
      "source": [
        "### **Langkah 3.8 - Compile Model CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QUIDJyfSWJB"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu20fiPFSWJC"
      },
      "source": [
        "Penggunaan loss function binary crossentropy dikarenakan kita hanya melakukan klasifikasi pada dua kelas, yaitu kucing dan anjing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dOcpQYgSWJC"
      },
      "source": [
        "## **Langkah 4 - Fit CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDYvbyC0SWJC",
        "outputId": "95110834-75da-4f79-99ca-b43ee4c27630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\Machine_Learning_2024\\.conda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.5496 - loss: 0.7004"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Machine Learning\\Machine_Learning_2024\\.conda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 267ms/step - accuracy: 0.5497 - loss: 0.7003 - val_accuracy: 0.7075 - val_loss: 0.5801\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.6853 - loss: 0.5975 - val_accuracy: 0.7295 - val_loss: 0.5397\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.7138 - loss: 0.5453 - val_accuracy: 0.7395 - val_loss: 0.5283\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - accuracy: 0.7337 - loss: 0.5325 - val_accuracy: 0.7520 - val_loss: 0.5220\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.7576 - loss: 0.5111 - val_accuracy: 0.7635 - val_loss: 0.5012\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - accuracy: 0.7612 - loss: 0.4799 - val_accuracy: 0.7590 - val_loss: 0.5091\n",
            "Epoch 7/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.7723 - loss: 0.4626 - val_accuracy: 0.7790 - val_loss: 0.4776\n",
            "Epoch 8/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.7776 - loss: 0.4562 - val_accuracy: 0.7805 - val_loss: 0.4755\n",
            "Epoch 9/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.7924 - loss: 0.4377 - val_accuracy: 0.7850 - val_loss: 0.4686\n",
            "Epoch 10/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.8045 - loss: 0.4198 - val_accuracy: 0.7730 - val_loss: 0.4720\n",
            "Epoch 11/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8060 - loss: 0.4187 - val_accuracy: 0.7940 - val_loss: 0.4597\n",
            "Epoch 12/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8173 - loss: 0.3970 - val_accuracy: 0.7920 - val_loss: 0.4534\n",
            "Epoch 13/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.8280 - loss: 0.3770 - val_accuracy: 0.7835 - val_loss: 0.4809\n",
            "Epoch 14/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.8240 - loss: 0.3831 - val_accuracy: 0.8040 - val_loss: 0.4302\n",
            "Epoch 15/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.8416 - loss: 0.3582 - val_accuracy: 0.7985 - val_loss: 0.4337\n",
            "Epoch 16/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - accuracy: 0.8374 - loss: 0.3655 - val_accuracy: 0.7995 - val_loss: 0.4528\n",
            "Epoch 17/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.8501 - loss: 0.3329 - val_accuracy: 0.8105 - val_loss: 0.4360\n",
            "Epoch 18/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8502 - loss: 0.3280 - val_accuracy: 0.7990 - val_loss: 0.4624\n",
            "Epoch 19/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8560 - loss: 0.3277 - val_accuracy: 0.8115 - val_loss: 0.4280\n",
            "Epoch 20/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8714 - loss: 0.3048 - val_accuracy: 0.8050 - val_loss: 0.4593\n",
            "Epoch 21/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.8726 - loss: 0.3029 - val_accuracy: 0.7990 - val_loss: 0.4737\n",
            "Epoch 22/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.8814 - loss: 0.2784 - val_accuracy: 0.8140 - val_loss: 0.4740\n",
            "Epoch 23/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.8802 - loss: 0.2800 - val_accuracy: 0.8045 - val_loss: 0.4929\n",
            "Epoch 24/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.8777 - loss: 0.2758 - val_accuracy: 0.8105 - val_loss: 0.4788\n",
            "Epoch 25/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - accuracy: 0.9017 - loss: 0.2441 - val_accuracy: 0.8080 - val_loss: 0.4785\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15529eba8a0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "4GZAnvVkSWJC"
      },
      "source": [
        "## **Langkah 5 - Prediksi dengan 1 Citra**\n",
        "Pada langkah ini, kita akan mencoba melakukan prediksi pada 1 citra anjing dan kucing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwbc3V7TSWJC",
        "outputId": "28b413ae-c2ee-42d3-aa0f-a784236e9670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image = image.load_img('data/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}